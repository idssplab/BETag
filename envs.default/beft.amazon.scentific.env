inters_path = dataset/amazon.scientific/inters.train.json
base_tags_path = dataset/amazon.scientific/base_tags.json
ckpt_dir = ckpts/amazon.scentific
max_seq_len = 15
min_seq_len = 3
n_tags_per_item = [0.8, 1.0]

num_epoch = 5

llm_name = 'MaziyarPanahi/Llama-3-8B-Instruct-v0.8'
lora_config__r = 64

training_config__learning_rate=1e-4
training_config__warmup_steps=1000
training_config__logging_steps=50
training_config__evaluation_strategy=no
training_config__gradient_accumulation_steps=1
training_config__per_device_train_batch_size=8
training_config__save_strategy=no
training_config__fp16=True